{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=28.81s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "\n",
    "coco = COCO('datasets/COCO/annotations/instances_train2017.json')\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "# print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgIds:  3502\n",
      "images:  3502\n"
     ]
    }
   ],
   "source": [
    "motorIds = coco.getCatIds(catNms=['motorcycle'])\n",
    "motorimgIds = coco.getImgIds(catIds=motorIds)\n",
    "motorimages = coco.loadImgs(motorimgIds)\n",
    "print(\"imgIds: \", len(motorimgIds))\n",
    "print(\"images: \", len(motorimages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in motorimages[0:1]:\n",
    "#     print(\"im: \", im)\n",
    "    img_data = requests.get(im['coco_url']).content\n",
    "    with open('datasets/COCO/images/' + im['file_name'], 'wb') as handler:\n",
    "        handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgIds:  64115\n",
      "images:  64115\n",
      "images:  10000\n"
     ]
    }
   ],
   "source": [
    "personIds = coco.getCatIds(catNms=['person'])\n",
    "perosnimgIds = coco.getImgIds(catIds=personIds)\n",
    "personimages = coco.loadImgs(perosnimgIds)\n",
    "print(\"imgIds: \", len(perosnimgIds))\n",
    "print(\"images: \", len(personimages))\n",
    "\n",
    "personimages = personimages[0:10000]\n",
    "print(\"images: \", len(personimages))\n",
    "# print(personimages[9999])\n",
    "\n",
    "# for im in personimages[5000:5001]:\n",
    "#     img_data = requests.get(\"http://images.cocodataset.org/train2017/\"+ im['file_name']).content\n",
    "#     with open('datasets/COCO/images_helmet/Person/' + im['file_name'], 'wb') as handler:\n",
    "#         handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motorcycle Images 3502\n",
      "Person Images 10000\n",
      "Helmet Images 11833\n",
      "3\n",
      "25335\n",
      "74958\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "json_dict = {\n",
    "    \"info\":{\n",
    "        \"year\": \"2020\",\n",
    "        \"version\": \"1\",\n",
    "        \"description\": \"Exported from COCO dataset\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"http://cocodataset.org/#detection-2017\",\n",
    "        \"date_created\": \"2020-04-23T04:36:14+00:00\"\n",
    "    },\n",
    "    \"license\":{\n",
    "            \"id\": 1,\n",
    "            \"url\": \"\",\n",
    "            \"name\": \"Unknown\"\n",
    "    },\n",
    "    \n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"Helmet\",\n",
    "            \n",
    "        }, \n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Motorcycle\",\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Person\",\n",
    "            \n",
    "        },\n",
    "  \n",
    "    ],\n",
    "    \n",
    "    \"images\": [], \"type\": \"instances\", \"annotations\": []}\n",
    "\n",
    "print(\"Motorcycle Images\",len(motorimages))\n",
    "for im in motorimages:\n",
    "    json_dict[\"images\"].append(im)\n",
    "    annIds = coco.getAnnIds(imgIds=im['id'], catIds=4, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for i in range(len(anns)):\n",
    "        annotation = {\n",
    "            'segmentation':[],\n",
    "             'area': anns[i]['area'],\n",
    "             'iscrowd': 0,\n",
    "             'image_id': anns[i]['image_id'],\n",
    "             'bbox':anns[i]['bbox'],\n",
    "             'category_id': 1,\n",
    "             'id':anns[i]['id']\n",
    "        }\n",
    "        json_dict[\"annotations\"].append(annotation)\n",
    "\n",
    "print(\"Person Images\",len(personimages))\n",
    "\n",
    "for im in personimages:\n",
    "    json_dict[\"images\"].append(im)\n",
    "    annIds = coco.getAnnIds(imgIds=im['id'], catIds=1, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for i in range(len(anns)):\n",
    "        annotation = {\n",
    "            'segmentation':[],\n",
    "             'area': anns[i]['area'],\n",
    "             'iscrowd': 0,\n",
    "             'image_id': anns[i]['image_id'],\n",
    "             'bbox':anns[i]['bbox'],\n",
    "             'category_id': 2,\n",
    "             'id':anns[i]['id']\n",
    "        }\n",
    "        json_dict[\"annotations\"].append(annotation)\n",
    "\n",
    "\n",
    "\n",
    "txt_files = glob.glob(os.path.join('helmet_images/images/', \"*.txt\"))\n",
    "print(\"Helmet Images\",len(txt_files))\n",
    "\n",
    "bnd_id = 0\n",
    "img_id = 0\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, \"r\") as tf:\n",
    "        lines = tf.readlines()\n",
    "        filedir = txt_file.split('/')[2].split('.')[0] + '.jpg'\n",
    "        img = cv2.imread('helmet_images/images/' + filedir)\n",
    "        height, width, depth = img.shape\n",
    "        images_tmp = {}\n",
    "        images_tmp[\"file_name\"] = filedir\n",
    "        images_tmp[\"height\"] = height\n",
    "        images_tmp[\"width\"] = width\n",
    "        images_tmp[\"id\"] = img_id\n",
    "        \n",
    "        json_dict[\"images\"].append(images_tmp)\n",
    "        for i in range(len(lines)):\n",
    "            tag_list = lines[i].split(' ')\n",
    "            yolo_x = float(tag_list[1])\n",
    "            yolo_y = float(tag_list[2])\n",
    "            yolo_w = float(tag_list[3])\n",
    "            yolo_h = float(tag_list[4])\n",
    "            x1, y1 = int((yolo_x - yolo_w/2)*width) , int((yolo_y - yolo_h/2)*height)\n",
    "            x2, y2 = int((yolo_x + yolo_w/2)*width), int(abs(yolo_y + yolo_h/2)*height)\n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            annotations_tmp = {}\n",
    "            annotations_tmp[\"id\"] = bnd_id\n",
    "            bnd_id += 1\n",
    "            annotations_tmp[\"image_id\"] = img_id\n",
    "            annotations_tmp[\"segmentation\"] = []\n",
    "            annotations_tmp[\"ignore\"] = 0\n",
    "            annotations_tmp[\"area\"] = (x2-x1)*(y2-y1)\n",
    "            annotations_tmp[\"iscrowd\"] = 0\n",
    "            annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1]\n",
    "            annotations_tmp[\"category_id\"] = 0\n",
    "            json_dict[\"annotations\"].append(annotations_tmp)\n",
    "            \n",
    "        img_id += 1\n",
    "# print(json_dict)\n",
    "\n",
    "print(len(json_dict['categories']))\n",
    "print(len(json_dict['images']))\n",
    "print(len(json_dict['annotations']))\n",
    "\n",
    "# print(len(json_dict))\n",
    "\n",
    "import os,json\n",
    "json_file = \"coco_dataset_3class/annotations/instances_Images.json\"\n",
    "os.makedirs(os.path.dirname(json_file), exist_ok=True)\n",
    "json_fp = open(json_file, \"w\")\n",
    "json_str = json.dumps(json_dict)\n",
    "json_fp.write(json_str)\n",
    "json_fp.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3502\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import glob,os,shutil\n",
    "# files = glob.glob(os.path.join('datasets/Dataset_nl/train/Helmet/', \"*.xml\"))\n",
    "# print(len(files))\n",
    "\n",
    "# for i in files:\n",
    "#     img_file = i.split('.')[0] + '.jpg'\n",
    "#     shutil.copy(img_file,\"datasets/COCO/images_helmet/Helmet/\")\n",
    "\n",
    "motor_files = []\n",
    "for i in glob.glob(os.path.join('datasets/COCO/images_helmet/Motorcycle/', \"*.jpg\")):\n",
    "    motor_files.append(i.split('/')[4])\n",
    "    \n",
    "person_files = []  \n",
    "for i in glob.glob(os.path.join('datasets/COCO/images_helmet/Person/', \"*.jpg\")):\n",
    "    person_files.append(i.split('/')[4])\n",
    "\n",
    "helmet_files = []\n",
    "for i in glob.glob(os.path.join('datasets/COCO/images_helmet/Helmet/', \"*.jpg\")):\n",
    "    helmet_files.append(i.split('/')[4])\n",
    "\n",
    "print(len(motor_files))\n",
    "print(len(person_files))\n",
    "# print(len(helmet_files))\n",
    "# os.mkdir(\"coco_dataset_3class/Images\")\n",
    "# os.mkdir(\"coco_dataset_3class/Images/Person\")\n",
    "# os.mkdir(\"coco_dataset_3class/Images/Motorcycle\")\n",
    "# os.mkdir(\"coco_dataset_3class/Images/Helmet\")\n",
    "\n",
    "\n",
    "# cnt = 0\n",
    "# for i in person_files:\n",
    "#     shutil.copy(\"datasets/COCO/images_helmet/Person/\" + i,\"coco_dataset_3class/Images/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
